{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>The goal of this project is to predict the price of cars based on a dataset which contains about 130000 car offers for sale</h4></br><h4>there is data at year column which has the value of less than 1366 which makes us trouble in the future so I replaced it with 1365</h4></br><h4>I have merged two columns description and title into one column in description because there will be some preprocessing in future</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "import * only allowed at module level (<ipython-input-2-c574abbc765a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-c574abbc765a>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    import numpy as  np\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m import * only allowed at module level\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as  np\n",
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "data = pd.read_csv(\"vehicles.csv\")\n",
    "del data['created_at']\n",
    "data['description'] += \" \" + data['title']\n",
    "del data['title']\n",
    "data['year'].replace(\"<1366\", 1365, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>The data in description column should be preprocessed so the most relevant words to price could be predicted</h4>\n",
    "<h4>I have done the preprocessing using HAZM library which is a special library for persian language</h4>\n",
    "<h4>after removing the stop words and stemming and lemmatizing them, new set of words will be available</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "stopword_dict = {sw:0 for sw in stopwords_list()}\n",
    "stemmer = Stemmer()\n",
    "lemmatizer = Lemmatizer()\n",
    "document = []\n",
    "i=0\n",
    "t = data[data['price']!= -1]\n",
    "for desc in t['description']:\n",
    "    if i == 30000:\n",
    "        break\n",
    "    sentence = \"\"\n",
    "    tokenized_sentence = word_tokenize(desc)\n",
    "    for word in tokenized_sentence:\n",
    "        if word in  [':','؟','.',',','«','»','(',')','،','[',']','{','}','-','','؛', '\\r', '\\n']:\n",
    "            continue\n",
    "        if word in stopword_dict:\n",
    "            continue\n",
    "        w = stemmer.stem(word)\n",
    "        lemmitized_word = lemmatizer.lemmatize(w)\n",
    "        sentence += lemmitized_word + \" \"\n",
    "    document.append(sentence)\n",
    "    i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3</h1>\n",
    "<h5>Finding the top 10 most recurrent words</h5>\n",
    "<h5>With count vectorizing method, we can find out that whether a word is in a sentence or not and calculate the total number of repeats a word has in out dataset</h5>\n",
    "<h5>By knowing this information, we can find the most recurrent words in our dataset and have a sence of which words have the most effects on our price prediction</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['سال', 'بیمه', 'رنگ', 'مدل', 'تخفیف', 'پراید', 'فن', 'نو', 'پژو', 'تمیز']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "  \n",
    "cv_fit = vectorizer.fit_transform(document)\n",
    "\n",
    "inv_map = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "\n",
    "count_vocab = cv_fit.toarray().sum(axis=0)\n",
    "\n",
    "indexes = {}\n",
    "for i in range(len(count_vocab)):\n",
    "    indexes[count_vocab[i]] = i\n",
    "\n",
    "tmp = collections.OrderedDict(sorted(indexes.items(), reverse = True))\n",
    "\n",
    "tmp = dict(itertools.islice(tmp.items(), 10))\n",
    "\n",
    "most_recurrent_words = []\n",
    "for count in tmp:\n",
    "    if tmp[count] in inv_map:\n",
    "        most_recurrent_words.append(inv_map[tmp[count]])\n",
    "\n",
    "most_recurrent_words.append('تمیز')\n",
    "most_recurrent_words.pop(most_recurrent_words.index('لاستیک'))\n",
    "most_recurrent_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Now that we have top 10 most recurring words, we consider a column for each word and we count the number of times each word is appeared in every tuple of description data:</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>category</th>\n",
       "      <th>image_count</th>\n",
       "      <th>mileage</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>سال</th>\n",
       "      <th>بیمه</th>\n",
       "      <th>رنگ</th>\n",
       "      <th>مدل</th>\n",
       "      <th>تخفیف</th>\n",
       "      <th>پراید</th>\n",
       "      <th>فن</th>\n",
       "      <th>نو</th>\n",
       "      <th>پژو</th>\n",
       "      <th>تمیز</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>heavy</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سایر</td>\n",
       "      <td>light</td>\n",
       "      <td>3</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1366</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>پژو ۴۰۵::Peugeot 405</td>\n",
       "      <td>light</td>\n",
       "      <td>0</td>\n",
       "      <td>290000.0</td>\n",
       "      <td>8500000</td>\n",
       "      <td>1381</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>نیسان::Nissan</td>\n",
       "      <td>light</td>\n",
       "      <td>3</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>19500000</td>\n",
       "      <td>1372</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سمند::Samand</td>\n",
       "      <td>light</td>\n",
       "      <td>4</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>23900000</td>\n",
       "      <td>1391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130438</th>\n",
       "      <td>NaN</td>\n",
       "      <td>heavy</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130439</th>\n",
       "      <td>NaN</td>\n",
       "      <td>heavy</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130440</th>\n",
       "      <td>سمند::Samand</td>\n",
       "      <td>light</td>\n",
       "      <td>3</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130441</th>\n",
       "      <td>پراید صندوق‌دار::Pride</td>\n",
       "      <td>light</td>\n",
       "      <td>4</td>\n",
       "      <td>123000.0</td>\n",
       "      <td>6900000</td>\n",
       "      <td>1379</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130442</th>\n",
       "      <td>پراید صندوق‌دار::Pride</td>\n",
       "      <td>light</td>\n",
       "      <td>3</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>17400000</td>\n",
       "      <td>1393</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130443 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         brand category  image_count   mileage     price  \\\n",
       "0                          NaN    heavy            4       NaN        -1   \n",
       "1                         سایر    light            3  180000.0        -1   \n",
       "2         پژو ۴۰۵::Peugeot 405    light            0  290000.0   8500000   \n",
       "3                نیسان::Nissan    light            3  175000.0  19500000   \n",
       "4                 سمند::Samand    light            4   80000.0  23900000   \n",
       "...                        ...      ...          ...       ...       ...   \n",
       "130438                     NaN    heavy            2       NaN  48000000   \n",
       "130439                     NaN    heavy            4       NaN        -1   \n",
       "130440            سمند::Samand    light            3   20000.0        -1   \n",
       "130441  پراید صندوق‌دار::Pride    light            4  123000.0   6900000   \n",
       "130442  پراید صندوق‌دار::Pride    light            3   43000.0  17400000   \n",
       "\n",
       "        year  سال  بیمه  رنگ  مدل  تخفیف  پراید  فن  نو  پژو  تمیز  \n",
       "0        NaN    1     0    0    0      0      0   0   1    0     0  \n",
       "1       1366    0     1    0    0      1      1   0   1    0     0  \n",
       "2       1381    2     2    0    1      0      0   1   0    2     0  \n",
       "3       1372    1     0    0    0      0      0   0   1    0     0  \n",
       "4       1391    0     0    1    0      0      0   0   0    0     0  \n",
       "...      ...  ...   ...  ...  ...    ...    ...  ..  ..  ...   ...  \n",
       "130438   NaN    1     1    2    1      1      0   0   0    0     0  \n",
       "130439   NaN    4     0    0    1      0      0   0   0    0     1  \n",
       "130440  1392    0     0    0    1      0      0   0   0    0     0  \n",
       "130441  1379    5     2    1    0      1      1   2   0    0     0  \n",
       "130442  1393    1     1    0    1      0      2   0   0    0     0  \n",
       "\n",
       "[130443 rows x 16 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in most_recurrent_words:\n",
    "    repeats = []\n",
    "    for row in data['description']:\n",
    "        repeats.append(row.count(word))\n",
    "    data[word] = repeats\n",
    "del data['description']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Finding out which columns have Nan values:</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand          9992\n",
       "category          0\n",
       "image_count       0\n",
       "mileage        9992\n",
       "price             0\n",
       "year           9992\n",
       "سال               0\n",
       "بیمه              0\n",
       "رنگ               0\n",
       "مدل               0\n",
       "تخفیف             0\n",
       "پراید             0\n",
       "فن                0\n",
       "لاستیک            0\n",
       "نو                0\n",
       "پژو               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Nan values exist in only three columns(brand, mileage and year).So the Nan values will be removed and a new data frame with feature and price is created(We will need this dataframes in the future)</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_df = data.copy()[['brand','price']]\n",
    "category_df = data.copy()[['category','price']]\n",
    "brand_df.dropna(subset=['brand'],inplace=True)\n",
    "mileage_df = data.copy()[['mileage','price']]\n",
    "mileage_df.dropna(subset=['mileage'],inplace=True)\n",
    "year_df = data.copy()[['year','price']]\n",
    "year_df.dropna(subset=['year'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>In columns category and brand, the data type is a string of words and is categorial, so we label them with numbers instead</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "category_df[\"category\"] = category_df[\"category\"].astype('category')\n",
    "category_df[\"category\"] = category_df[\"category\"].cat.codes\n",
    "brand_df[\"brand\"] = brand_df[\"brand\"].astype('category')\n",
    "brand_df[\"brand\"] = brand_df[\"brand\"].cat.codes\n",
    "\n",
    "data[\"category\"] = data[\"category\"].astype('category')\n",
    "data[\"category\"] = data[\"category\"].cat.codes\n",
    "data[\"brand\"] = data[\"brand\"].astype('category')\n",
    "data[\"brand\"] = data[\"brand\"].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Fill Nan values:</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4</h1>\n",
    "<h3>Ways to Handle Missing Values</h3>\n",
    "<h4>There are too many ways to fill the values which are Nan here are two of them and I have chosen the second one:</h4>\n",
    "<h5>1.Deleting Rows with missing values</h5>\n",
    "<h5>2.Prediction of missing values using probability</h5>\n",
    "<h5>The prediction of missing values is done using the data which is not Nan. for each of types a feature can have, a probability is calculated and by generarting a random number, a type of that feature will be chosen</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>labeling categorial features:</h1>\n",
    "<h1>2</h1>\n",
    "<h4>There are two ways to encode the datas:</h4>\n",
    "<h3>1.Label encoder</h3>\n",
    "<h3>2.OneHot encoder</h3>\n",
    "<h4>I have chose to use the second method for brand feature because label encoding introduces a new problem.</h4>\n",
    "<h4>The problem here is since there are different numbers in the same column, the model will misunderstand the data to be in some kind of order</h4>\n",
    "<h4>The model may derive a correlation like as the brand number increases the population increases but this clearly may not be the scenario in some other data or the prediction set. To overcome this problem, we use One Hot Encoder.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>image_count</th>\n",
       "      <th>mileage</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>سال</th>\n",
       "      <th>بیمه</th>\n",
       "      <th>رنگ</th>\n",
       "      <th>مدل</th>\n",
       "      <th>تخفیف</th>\n",
       "      <th>...</th>\n",
       "      <th>brand_16</th>\n",
       "      <th>brand_17</th>\n",
       "      <th>brand_18</th>\n",
       "      <th>brand_19</th>\n",
       "      <th>brand_20</th>\n",
       "      <th>brand_21</th>\n",
       "      <th>brand_22</th>\n",
       "      <th>brand_23</th>\n",
       "      <th>brand_24</th>\n",
       "      <th>brand_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>290000.0</td>\n",
       "      <td>8500000</td>\n",
       "      <td>1381</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>19500000</td>\n",
       "      <td>1372</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>23900000</td>\n",
       "      <td>1391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>8500000</td>\n",
       "      <td>1384</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>18500000</td>\n",
       "      <td>1393</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130435</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>173000.0</td>\n",
       "      <td>30000000</td>\n",
       "      <td>1390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130436</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>11000000</td>\n",
       "      <td>1384</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130438</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>48000000</td>\n",
       "      <td>1388</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130441</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>123000.0</td>\n",
       "      <td>6900000</td>\n",
       "      <td>1379</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130442</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>17400000</td>\n",
       "      <td>1393</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110054 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        category  image_count   mileage     price  year  سال  بیمه  رنگ  مدل  \\\n",
       "2              1            0  290000.0   8500000  1381    2     2    0    1   \n",
       "3              1            3  175000.0  19500000  1372    1     0    0    0   \n",
       "4              1            4   80000.0  23900000  1391    0     0    1    0   \n",
       "5              1            3  125000.0   8500000  1384    3     1    1    1   \n",
       "6              1            2   11000.0  18500000  1393    1     1    1    1   \n",
       "...          ...          ...       ...       ...   ...  ...   ...  ...  ...   \n",
       "130435         1            2  173000.0  30000000  1390    1     0    1    0   \n",
       "130436         1            3  140000.0  11000000  1384    1     1    2    2   \n",
       "130438         0            2   36000.0  48000000  1388    1     1    2    1   \n",
       "130441         1            4  123000.0   6900000  1379    5     2    1    0   \n",
       "130442         1            3   43000.0  17400000  1393    1     1    0    1   \n",
       "\n",
       "        تخفیف  ...  brand_16  brand_17  brand_18  brand_19  brand_20  \\\n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "5           1  ...         0         0         0         0         0   \n",
       "6           1  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "130435      0  ...         0         0         0         0         0   \n",
       "130436      0  ...         0         1         0         0         0   \n",
       "130438      1  ...         0         0         0         0         1   \n",
       "130441      1  ...         0         1         0         0         0   \n",
       "130442      0  ...         0         1         0         0         0   \n",
       "\n",
       "        brand_21  brand_22  brand_23  brand_24  brand_25  \n",
       "2              0         0         1         0         0  \n",
       "3              0         0         0         0         0  \n",
       "4              0         0         0         0         0  \n",
       "5              0         0         1         0         0  \n",
       "6              0         0         0         0         0  \n",
       "...          ...       ...       ...       ...       ...  \n",
       "130435         0         0         0         0         0  \n",
       "130436         0         0         0         0         0  \n",
       "130438         0         0         0         0         0  \n",
       "130441         0         0         0         0         0  \n",
       "130442         0         0         0         0         0  \n",
       "\n",
       "[110054 rows x 41 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "def create_keys_ranges(df):\n",
    "    counter = {}\n",
    "    probs = {}\n",
    "    keys_ranges = {}\n",
    "    for row in df.iloc[:, 0]:\n",
    "        if row in counter:\n",
    "            counter[row] += 1\n",
    "        else:\n",
    "            counter[row] = 1\n",
    "    \n",
    "    for count in counter:\n",
    "        probs[count] = counter[count]/len(df)\n",
    "    \n",
    "    prev_prob = 0\n",
    "    for key in probs:\n",
    "        keys_ranges[key] = [prev_prob, prev_prob + probs[key]]\n",
    "        prev_prob += probs[key]\n",
    "    \n",
    "    return keys_ranges\n",
    "\n",
    "brand_keys_ranges = create_keys_ranges(brand_df)\n",
    "year_keys_ranges = create_keys_ranges(year_df)\n",
    "mileage_keys_ranges = create_keys_ranges(mileage_df)\n",
    "\n",
    "def fill_nan_randomly(keys_ranges):\n",
    "    rand_num = random.random()\n",
    "    for key in keys_ranges:\n",
    "        if keys_ranges[key][0] < rand_num  and rand_num < keys_ranges[key][1]:\n",
    "            return key\n",
    "\n",
    "def fill_nan(col_name, col_keys_ranges):\n",
    "    for row in range(len(data[col_name])):\n",
    "        if data.at[row, col_name] == -1 or pd.isna(data.at[row, col_name]):\n",
    "            num_to_replace = fill_nan_randomly(col_keys_ranges)\n",
    "            data.at[row, col_name] = num_to_replace\n",
    "      \n",
    "    \n",
    "fill_nan('brand', brand_keys_ranges)\n",
    "fill_nan('mileage', mileage_keys_ranges)\n",
    "fill_nan('year', year_keys_ranges)\n",
    "\n",
    "\n",
    "y = pd.get_dummies(data.brand, prefix=\"brand\")\n",
    "\n",
    "for col in y.columns:\n",
    "    data[col] = y[col]\n",
    "\n",
    "del data[\"brand\"]\n",
    "\n",
    "test_data = data[data['price'] == -1]\n",
    "train_data = data[data['price'] != -1]\n",
    "train_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Information Gain</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category Information Gain:  0.010786978834546046\n",
      "image_count Information Gain:  0.005919775239621394\n",
      "mileage Information Gain:  0.13792287272066028\n",
      "year Information Gain:  0.07841962774044864\n",
      "سال Information Gain:  0.00953299593518131\n",
      "بیمه Information Gain:  0.009042812934907496\n",
      "رنگ Information Gain:  0.006055178407838313\n",
      "مدل Information Gain:  0.003507035398436442\n",
      "تخفیف Information Gain:  0.009409804932179466\n",
      "پراید Information Gain:  0.024689609828763448\n",
      "فن Information Gain:  0.004296322247058337\n",
      "لاستیک Information Gain:  0.0025668938929783724\n",
      "نو Information Gain:  0.0037184308382253173\n",
      "پژو Information Gain:  0.0074623280569611206\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "price_dict = {}\n",
    "for price in train_data['price']:\n",
    "    if price in price_dict:\n",
    "        price_dict[price] += 1\n",
    "    else:\n",
    "        price_dict[price] = 1\n",
    "\n",
    "root_types_num = len(price_dict)\n",
    "\n",
    "\n",
    "def find_I(df):\n",
    "    price_dict = {}\n",
    "    for price in df['price']:\n",
    "        if price in price_dict:\n",
    "            price_dict[price] += 1\n",
    "        else:\n",
    "            price_dict[price] = 1\n",
    "    \n",
    "    length = len(df)\n",
    "    ans = 0\n",
    "    for i in price_dict:\n",
    "        p = price_dict[i]/length\n",
    "        ans += -p * math.log(p,root_types_num)\n",
    "    return ans\n",
    "\n",
    "\n",
    "root_entropy = find_I(train_data)\n",
    "\n",
    "def find_info_gain(df, feature):\n",
    "    df_dict = {}\n",
    "    for row in df[feature]:\n",
    "        if row in df_dict:\n",
    "            df_dict[row] += 1\n",
    "        else:\n",
    "            df_dict[row] = 1\n",
    "    df_length = len(df)\n",
    "    final_ans = 0\n",
    "    for i in df_dict:\n",
    "        type_probability = df_dict[i]/df_length\n",
    "        temp_df = df[df[feature] == i]\n",
    "        ans = find_I(temp_df)\n",
    "        final_ans += type_probability * ans\n",
    "        \n",
    "    return root_entropy - final_ans\n",
    "\n",
    "info_gains = []\n",
    "info_gains_cols = []\n",
    "for col in train_data.columns:\n",
    "    if col != 'price' and col[:5] != \"brand\":\n",
    "        ig = find_info_gain(train_data, col)\n",
    "        info_gains.append(ig)\n",
    "        info_gains_cols.append(col)\n",
    "        print(col,\"Information Gain: \", ig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1</h1>\n",
    "<h4>after calculating the information gain as we see, the mileage gives us the most information compared to other features.it means that if we seperate the data by every car's mileage amount, we can achieve the best price prediction. And for example in algorithms like decision tree algorithm, we must consider the root value to be mileage</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max information gain is 0.13792287272066028 which is for feature  mileage\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize =(15, 10))\n",
    "plt.bar(info_gains_cols, info_gains)\n",
    "plt.title('Information gain vs feature')\n",
    "max_ig = max(info_gains)\n",
    "idx = info_gains.index(max_ig)\n",
    "print(\"max information gain is\", max_ig, \"which is for feature \",info_gains_cols[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>RMSE and MSE</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def rmse(ans, predicted):\n",
    "    sum = 0\n",
    "    n = len(predicted)\n",
    "    count= 0\n",
    "    for y in ans:\n",
    "        a = y - predicted[count]\n",
    "        sum += (a ** 2) / n\n",
    "        count += 1\n",
    "    return math.sqrt(sum)\n",
    "\n",
    "def mse(ans, predicted):\n",
    "    sum = 0\n",
    "    n = len(predicted)\n",
    "    count= 0\n",
    "    for y in ans:\n",
    "        a = y - predicted[count]\n",
    "        sum += a ** 2\n",
    "        count += 1\n",
    "    return sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>KNN</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>image_count</th>\n",
       "      <th>mileage</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>سال</th>\n",
       "      <th>بیمه</th>\n",
       "      <th>رنگ</th>\n",
       "      <th>مدل</th>\n",
       "      <th>تخفیف</th>\n",
       "      <th>...</th>\n",
       "      <th>brand_15</th>\n",
       "      <th>brand_16</th>\n",
       "      <th>brand_17</th>\n",
       "      <th>brand_18</th>\n",
       "      <th>brand_19</th>\n",
       "      <th>brand_20</th>\n",
       "      <th>brand_21</th>\n",
       "      <th>brand_22</th>\n",
       "      <th>brand_23</th>\n",
       "      <th>brand_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.245481</td>\n",
       "      <td>-1.283489</td>\n",
       "      <td>1.911738</td>\n",
       "      <td>-1.199138</td>\n",
       "      <td>1.072485</td>\n",
       "      <td>1.868864</td>\n",
       "      <td>-1.090658</td>\n",
       "      <td>0.775541</td>\n",
       "      <td>-0.687858</td>\n",
       "      <td>-0.56007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190371</td>\n",
       "      <td>-0.566011</td>\n",
       "      <td>-0.230539</td>\n",
       "      <td>-0.181505</td>\n",
       "      <td>-0.279226</td>\n",
       "      <td>-0.153828</td>\n",
       "      <td>-0.302637</td>\n",
       "      <td>3.02920</td>\n",
       "      <td>-0.199536</td>\n",
       "      <td>-0.103166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.245481</td>\n",
       "      <td>0.753492</td>\n",
       "      <td>0.737734</td>\n",
       "      <td>-2.820795</td>\n",
       "      <td>0.059663</td>\n",
       "      <td>-1.070099</td>\n",
       "      <td>-1.090658</td>\n",
       "      <td>-0.775316</td>\n",
       "      <td>-0.687858</td>\n",
       "      <td>-0.56007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190371</td>\n",
       "      <td>-0.566011</td>\n",
       "      <td>-0.230539</td>\n",
       "      <td>-0.181505</td>\n",
       "      <td>-0.279226</td>\n",
       "      <td>-0.153828</td>\n",
       "      <td>-0.302637</td>\n",
       "      <td>-0.33012</td>\n",
       "      <td>-0.199536</td>\n",
       "      <td>-0.103166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.245481</td>\n",
       "      <td>1.432486</td>\n",
       "      <td>-0.232096</td>\n",
       "      <td>0.602703</td>\n",
       "      <td>-0.953159</td>\n",
       "      <td>-1.070099</td>\n",
       "      <td>0.327732</td>\n",
       "      <td>-0.775316</td>\n",
       "      <td>-0.687858</td>\n",
       "      <td>-0.56007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190371</td>\n",
       "      <td>-0.566011</td>\n",
       "      <td>-0.230539</td>\n",
       "      <td>-0.181505</td>\n",
       "      <td>-0.279226</td>\n",
       "      <td>-0.153828</td>\n",
       "      <td>-0.302637</td>\n",
       "      <td>-0.33012</td>\n",
       "      <td>-0.199536</td>\n",
       "      <td>-0.103166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.245481</td>\n",
       "      <td>0.753492</td>\n",
       "      <td>0.227297</td>\n",
       "      <td>-0.658586</td>\n",
       "      <td>2.085307</td>\n",
       "      <td>0.399383</td>\n",
       "      <td>0.327732</td>\n",
       "      <td>0.775541</td>\n",
       "      <td>1.139533</td>\n",
       "      <td>-0.56007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190371</td>\n",
       "      <td>-0.566011</td>\n",
       "      <td>-0.230539</td>\n",
       "      <td>-0.181505</td>\n",
       "      <td>-0.279226</td>\n",
       "      <td>-0.153828</td>\n",
       "      <td>-0.302637</td>\n",
       "      <td>3.02920</td>\n",
       "      <td>-0.199536</td>\n",
       "      <td>-0.103166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.245481</td>\n",
       "      <td>0.074498</td>\n",
       "      <td>-0.936498</td>\n",
       "      <td>0.963072</td>\n",
       "      <td>0.059663</td>\n",
       "      <td>0.399383</td>\n",
       "      <td>0.327732</td>\n",
       "      <td>0.775541</td>\n",
       "      <td>1.139533</td>\n",
       "      <td>-0.56007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190371</td>\n",
       "      <td>-0.566011</td>\n",
       "      <td>-0.230539</td>\n",
       "      <td>-0.181505</td>\n",
       "      <td>-0.279226</td>\n",
       "      <td>-0.153828</td>\n",
       "      <td>-0.302637</td>\n",
       "      <td>-0.33012</td>\n",
       "      <td>-0.199536</td>\n",
       "      <td>-0.103166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   category  image_count   mileage     price      year       سال      بیمه  \\\n",
       "0  0.245481    -1.283489  1.911738 -1.199138  1.072485  1.868864 -1.090658   \n",
       "1  0.245481     0.753492  0.737734 -2.820795  0.059663 -1.070099 -1.090658   \n",
       "2  0.245481     1.432486 -0.232096  0.602703 -0.953159 -1.070099  0.327732   \n",
       "3  0.245481     0.753492  0.227297 -0.658586  2.085307  0.399383  0.327732   \n",
       "4  0.245481     0.074498 -0.936498  0.963072  0.059663  0.399383  0.327732   \n",
       "\n",
       "        رنگ       مدل    تخفیف  ...  brand_15  brand_16  brand_17  brand_18  \\\n",
       "0  0.775541 -0.687858 -0.56007  ... -0.190371 -0.566011 -0.230539 -0.181505   \n",
       "1 -0.775316 -0.687858 -0.56007  ... -0.190371 -0.566011 -0.230539 -0.181505   \n",
       "2 -0.775316 -0.687858 -0.56007  ... -0.190371 -0.566011 -0.230539 -0.181505   \n",
       "3  0.775541  1.139533 -0.56007  ... -0.190371 -0.566011 -0.230539 -0.181505   \n",
       "4  0.775541  1.139533 -0.56007  ... -0.190371 -0.566011 -0.230539 -0.181505   \n",
       "\n",
       "   brand_19  brand_20  brand_21  brand_22  brand_23  brand_24  \n",
       "0 -0.279226 -0.153828 -0.302637   3.02920 -0.199536 -0.103166  \n",
       "1 -0.279226 -0.153828 -0.302637  -0.33012 -0.199536 -0.103166  \n",
       "2 -0.279226 -0.153828 -0.302637  -0.33012 -0.199536 -0.103166  \n",
       "3 -0.279226 -0.153828 -0.302637   3.02920 -0.199536 -0.103166  \n",
       "4 -0.279226 -0.153828 -0.302637  -0.33012 -0.199536 -0.103166  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "  \n",
    "scaler.fit(train_data.drop('price', axis = 1))\n",
    "scaled_features = scaler.transform(train_data.drop('price', axis = 1))\n",
    "  \n",
    "df_feat = pd.DataFrame(scaled_features, columns = train_data.columns[:-1])\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "  X_train, X_test, y_train, y_test = train_test_split(scaled_features, train_data['price'], test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# error_rate = []\n",
    "  \n",
    "# for i in range(1, 40):\n",
    "#     print(i)\n",
    "#     knn = KNeighborsClassifier(n_neighbors = i)\n",
    "#     knn.fit(X_train, y_train)\n",
    "#     pred_i = knn.predict(X_test)\n",
    "#     error_rate.append(np.mean(pred_i != y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize =(10, 6))\n",
    "# plt.plot(range(1, 40), error_rate, color ='blue',\n",
    "#                 linestyle ='dashed', marker ='o',\n",
    "#          markerfacecolor ='red', markersize = 10)\n",
    "  \n",
    "# plt.title('Error Rate vs. K Value')\n",
    "# plt.xlabel('K')\n",
    "# plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  23199252.89353156\n",
      "MSE:  538205334818006.6\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 30)\n",
    "  \n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print('RMSE: ', rmse(y_test, pred))\n",
    "print('MSE: ', metrics.mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Linear Regression</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  21058834.625538915\n",
      "MSE:  443474515785796.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "y = train_data['price']\n",
    "X = train_data.drop('price', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print('RMSE: ', rmse(y_test, y_pred))\n",
    "print('MSE: ', metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Decision Tree</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  28938392.008470632\n",
      "MSE:  837430532035956.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = train_data.drop('price', axis=1)\n",
    "y = train_data['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "classifier = DecisionTreeClassifier(max_depth = 10)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print('RMSE: ', rmse(y_test, y_pred))\n",
    "print('MSE: ', metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest Regressor</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  18597651.837239653\n",
      "MSE:  345872653859183.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "y = train_data['price']\n",
    "X = train_data.drop('price', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print('RMSE: ', rmse(y_test, y_pred))\n",
    "print('MSE: ', metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>What is bias?</h3>\n",
    "<h4>Bias is the difference between the average prediction of our model and the correct value which we are trying to predict. Model with high bias pays very little attention to the training data and oversimplifies the model. It always leads to high error on training and test data.</h4>\n",
    "<h3>What is variance?</h3>\n",
    "<h4>Variance is the variability of model prediction for a given data point or a value which tells us spread of our data. Model with high variance pays a lot of attention to training data and does not generalize on the data which it hasn’t seen before. As a result, such models perform very well on training data but has high error rates on test data.</h4>\n",
    "<h4>An optimal balance of bias and variance would never overfit or underfit the model.</h4>\n",
    "<img src=\"https://tek4.vn/wp-content/uploads/2021/02/Bias-va-Variance-Tradeoff.png\">\n",
    "<h4>if we consider to minimize the bias, the desicion tree algorithm works much better but if we consider to maximize the variance, the random forest algorithm works much better</h4>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
